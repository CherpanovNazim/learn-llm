{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CherpanovNazim/learn-llm/blob/main/notebooks/02_Information_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaOhiiXn8WO-"
      },
      "source": [
        "\n",
        "> [GitHub Repo](https://github.com/CherpanovNazim/learn-llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCLCxVKoZ8n0"
      },
      "outputs": [],
      "source": [
        "#clone git repository\n",
        "!git clone -q https://github.com/CherpanovNazim/learn-llm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSxf4LBw8WO_"
      },
      "outputs": [],
      "source": [
        "# wait ~3 min for installations\n",
        "%%time\n",
        "\n",
        "!pip install -qU thefuzz==0.22.1 openai==1.40.3 vllm==0.5.4 transformers==4.44.0 langchain==0.2.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTq6lYY99IxI"
      },
      "outputs": [],
      "source": [
        "# wait ~3 min for installations\n",
        "%%time\n",
        "\n",
        "import json\n",
        "import  sys\n",
        "\n",
        "# Load the default model\n",
        "DEFAULT_MODEL = json.load(open('learn-llm/configs/llama_3_8B_instruct_awq.json', 'r'))\n",
        "\n",
        "#run VLLM\n",
        "!nohup vllm serve {DEFAULT_MODEL['model']} --quantization awq --max-model-len=4096 > vllm.log &\n",
        "!tail -f vllm.log | grep -q \"Uvicorn running\" && echo \"Now you can start using the model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1R-4YnK8WPB"
      },
      "outputs": [],
      "source": [
        "!python3 learn-llm\\notebooks\\utils\\explainer.py\n",
        "sys.path.append('learn-llm/notebooks/utils')\n",
        "\n",
        "from explainer import Explainer\n",
        "\n",
        "explain = Explainer(DEFAULT_MODEL)\n",
        "# use this class if you want to get some explanations\n",
        "explain(\"Explain what is NER in NLP in short\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKW-beHG8WPB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set the base URL and API key\n",
        "# For production apps it's preferable to use some secret management system and don't store the key in git repo :)\n",
        "client = openai.OpenAI(\n",
        "    base_url = DEFAULT_MODEL['api_base'],\n",
        "    api_key = DEFAULT_MODEL['api_key']\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b11_UjZz8WPB"
      },
      "source": [
        "# Named Entity Recognition (NER)\n",
        "* We use a small sample from [Few-NERD](https://github.com/thunlp/Few-NERD) dataset with 4 entity types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C44eFlql8WPB"
      },
      "outputs": [],
      "source": [
        "dataset_df = pd.read_json('learn-llm/data/fewnerd_NER.json', lines=True)\n",
        "\n",
        "unique_entities = ['product_food', 'building_restaurant', 'organization_company', 'location_gpe']\n",
        "\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH1KGbup8WPB"
      },
      "outputs": [],
      "source": [
        "print(dataset_df.iloc[0]['text'])\n",
        "print('\\nLabels:')\n",
        "pprint(dataset_df.iloc[0]['labels'])\n",
        "\n",
        "# note that there is no \"product-food\" entity there for this example :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQFvs5Gm8WPB"
      },
      "source": [
        "# Evaluation\n",
        "* Let's first of all define the evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQXLj3Z28WPB"
      },
      "outputs": [],
      "source": [
        "!python3 learn-llm\\notebooks\\utils\\ner_fuzzy_score.py\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ner_fuzzy_score import calculate_mean_score\n",
        "\n",
        "train_df, test_df = train_test_split(dataset_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# example of metric calculation\n",
        "calculate_mean_score(y_true = [{'product_food': ['chicken nuggets', 'rice'], 'place_restaurant': ['McDonalds']}],\n",
        "                     y_pred = [{'product_food': ['rice', 'chicken', 'FALSE']}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzbqg8O78WPC"
      },
      "outputs": [],
      "source": [
        "def text_completion(prompt, temperature=0, max_tokens=2, return_completion_only=True, **kwargs):\n",
        "    completion_response = client.completions.create(\n",
        "                            model=DEFAULT_MODEL[\"model\"],\n",
        "                            temperature=temperature,\n",
        "                            max_tokens=max_tokens,\n",
        "                            prompt=prompt,\n",
        "                            **kwargs)\n",
        "    if return_completion_only:\n",
        "        return completion_response.choices[0].text.strip()\n",
        "    else:\n",
        "        return completion_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsbSA4no8WPC"
      },
      "source": [
        "# JSON Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BQMvFrv8WPC"
      },
      "source": [
        "LLMs not always returns just a JSON, so we need to correctly extract and parse it. There are few options available:\n",
        "* [JSON mode](https://platform.openai.com/docs/guides/json-mode) provided by OpenAI forses responce to output a JSON format.\n",
        "* In this notebook we are using vLLM functionality to recieve outputs in JSON format. This requires passing sample JSON schema to recieve correct output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n1izz2L8WPC"
      },
      "source": [
        "JSON schema shapes LLM's output, so it is crucial to correctly initialize it.\n",
        "\n",
        "In some use-cases prior information about presence or exact number of entities might be available, so we should include it in our JSON:\n",
        "- **min_items = 1** : model should include at least one entry\n",
        "- **Optional** : entries could be *None*\n",
        "\n",
        "These parameters help LLM correctly shape final output in our case, which resulted in overall better performance. <br />\n",
        "\n",
        "Depending on the case additional fields (E.g. **unique_items**, **max_digits**) might be added for more specific structure. <br />\n",
        "All supported parameters could be found in [Pydantic documentation](https://docs.pydantic.dev/1.10/usage/schema/#field-customization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWpl9crI8WPC"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, conlist\n",
        "from typing import List, Optional\n",
        "import json\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Entities(BaseModel):\n",
        "    product_food: Optional[List[str]] = Field(..., min_items = 1)\n",
        "    building_restaurant: Optional[List[str]] = Field(..., min_items = 1)\n",
        "    organization_company: Optional[List[str]] = Field(..., min_items = 1)\n",
        "    location_gpe: Optional[List[str]] = Field(..., min_items = 1)\n",
        "\n",
        "sample_json_schema = Entities.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ef_-5M38WPC"
      },
      "outputs": [],
      "source": [
        "def chat_completion(prompts, temperature=0, max_tokens=2, system_prompt: str = None, json_schema = sample_json_schema, **kwargs):\n",
        "    if system_prompt is None:\n",
        "        system_prompt = \"Just follow user instructions and don't communicate like \\\"Sure!\\\" or \\\"I hope this helps\\\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL[\"model\"],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                  {\"role\": \"user\", \"content\": prompts}],\n",
        "        extra_body=dict(guided_json = json_schema),\n",
        "        **kwargs\n",
        "        )\n",
        "    return completion.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK2GyIfR8WPD"
      },
      "outputs": [],
      "source": [
        "def llm_predict(text, template):\n",
        "    prompt = template.format(text=text)\n",
        "    prediction = chat_completion(prompt, max_tokens=200).lower().strip()\n",
        "    out = json.loads(prediction)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM1-KLz18WPD"
      },
      "source": [
        "# Zero-shot NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GODY4Gg68WPD"
      },
      "outputs": [],
      "source": [
        "zero_shot_template = \"\"\"\\\n",
        "You will get a text and you should extract entities from it.\n",
        "Format your answer in a JSON format with keys: product_food, building_restaurant, organization_company, location_gpe.\n",
        "Each key should have a list of entities.\n",
        "\n",
        "Text: \"{text}\"\n",
        "\"\"\"\n",
        "\n",
        "zero_shot_predictions = list(map(partial(llm_predict, template=zero_shot_template), tqdm(test_df.text)))\n",
        "\n",
        "print('Score:')\n",
        "pprint(calculate_mean_score(test_df.labels, zero_shot_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMJYGcOw8WPD"
      },
      "source": [
        "# Few-shot NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f8ZN6_L8WPD"
      },
      "outputs": [],
      "source": [
        "def get_few_shot_example(df, n=1, seed=None):\n",
        "    examples_str = ''\n",
        "    for _,row in df.sample(n, random_state=seed, ).iterrows():\n",
        "        json_str = ''\n",
        "        if row.labels != {}:\n",
        "            # keep the same order of entities (keys) as in the dataset\n",
        "            # if there is no entity in the text - it will be empty list\n",
        "            # additional { and } are needed for escaping - it will keep only ony after second .format\n",
        "\n",
        "            json_str = '{'+json.dumps({k:row.labels.get(k, []) for k in unique_entities})+'}'\n",
        "            #json_str = '{'+json.dumps({k:row.labels[k] for k in unique_entities if k in row.labels})+'}'\n",
        "\n",
        "        examples_str += 'Text: \"{}\"\\nJSON: {}\\n\\n'.format(row.text, json_str)\n",
        "    return examples_str.strip()\n",
        "\n",
        "print(get_few_shot_example(train_df, n=1, seed=42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tckgCA-18WPD"
      },
      "outputs": [],
      "source": [
        "few_shot_template = \"\"\"\\\n",
        "You will get a text and you should extract entities from it.\n",
        "Format your answer in a JSON format with keys: product_food, building_restaurant, organization_company, location_gpe.\n",
        "Each key should have a list of entities.\n",
        "\n",
        "{few_shot_examples}\n",
        "\n",
        "Text: \"{{text}}\"\n",
        "JSON:\n",
        "\"\"\"\n",
        "\n",
        "# we randomly select 5 few-shot examples from the train dataset\n",
        "few_shot_examples = get_few_shot_example(train_df, n=5, seed=42)\n",
        "\n",
        "# fill-in the template with few-shot examples\n",
        "filled_few_shot_template = few_shot_template.format(few_shot_examples=few_shot_examples)\n",
        "\n",
        "# make predictions\n",
        "few_shot_predictions = list(map(partial(llm_predict, template=filled_few_shot_template), tqdm(test_df.text)))\n",
        "\n",
        "print('Score:')\n",
        "pprint(calculate_mean_score(test_df.labels, few_shot_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4S3JURY8WPD"
      },
      "source": [
        "# Relation extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS_eZiNA8WPD"
      },
      "source": [
        "* Unfortunately is doesn't work well with LLAMA 3\n",
        "* _TODO_: test with other models like GPT or Mistral\\Zephyr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChdUGwSj8WPD"
      },
      "outputs": [],
      "source": [
        "explain('What is relation extraction in NLP and how it connected to NER ? make a short summary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9QvZMjx8WPE"
      },
      "source": [
        "# Summary\n",
        "* Correct parsing of response is very important\n",
        "* Zero-shot learning is very powerful and can be used for many tasks\n",
        "* There are special tools for NER and REL tasks\n",
        "* Few-shot learning might NOT boost your performance (for some reason he-he _TODO_: find out why)\n",
        "* Relation extraction can help to identify relations between entities in text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vf1arI8WPE"
      },
      "source": [
        "# Extra\n",
        "* There are pre-trained LLMs specifically for Information Extraction\n",
        "* * [GoLLIE](https://github.com/hitz-zentroa/GoLLIE) - pre-trained LLM for zero-shot Information Extraction with annotation schemas defined on the fly (Apache 2)\n",
        "* * [UniversalNER](https://universal-ner.github.io/) - instruction-tuned LLM for NER for zero-shot IE (non commercial ?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnpXxAUx8WPE"
      },
      "source": [
        "# Homework\n",
        "* Try to play with prompts in order to improve accuracy\n",
        "* Try to extract PRICE from reviews in amazon_food_reviews_sample.csv dataset and identify the overall price for each of 6 products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhovsQRj8WPE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews_df = pd.read_csv('learn-llm/data/amazon_food_reviews_sample.csv')\n",
        "reviews_df.ProductId.value_counts()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

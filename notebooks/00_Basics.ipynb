{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CherpanovNazim/learn-llm/blob/main/notebooks/00_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ac8f20d",
      "metadata": {
        "id": "0ac8f20d"
      },
      "source": [
        "* [GitHub Repo](https://github.com/CherpanovNazim/learn-llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61372fac",
      "metadata": {
        "id": "61372fac"
      },
      "outputs": [],
      "source": [
        "#clone git repository\n",
        "!git clone -q https://github.com/CherpanovNazim/learn-llm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af19ed4",
      "metadata": {
        "id": "5af19ed4"
      },
      "outputs": [],
      "source": [
        "# wait ~3 min for installations\n",
        "%%time\n",
        "\n",
        "!pip install -qU openai==1.40.3 vllm==0.5.4 transformers==4.44.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LbYR367oX3i-",
      "metadata": {
        "id": "LbYR367oX3i-"
      },
      "outputs": [],
      "source": [
        "# wait ~2 min for installations\n",
        "%%time\n",
        "\n",
        "import json\n",
        "import sys\n",
        "\n",
        "# Load the default model\n",
        "DEFAULT_MODEL = json.load(open('learn-llm/configs/llama_3_8B_instruct_awq.json', 'r'))\n",
        "\n",
        "#run VLLM\n",
        "!nohup vllm serve {DEFAULT_MODEL['model']} --quantization awq --max-model-len=4096 > vllm.log &\n",
        "!tail -f vllm.log | grep -q \"Uvicorn running\" && echo \"Now you can start using the model\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b064a83c",
      "metadata": {
        "id": "b064a83c"
      },
      "source": [
        "# Why LLAMA 3 ?\n",
        "\n",
        "* We mainly use GPT 3.5 or GPT 4 models for production use-cases\n",
        "* For this course we use LLAMA 3 8B model for educational purposes\n",
        "* LLAMA 3 is smaller, but still very powerful\n",
        "* We use OpenAI-compatible API for our LLAMA 3 - so this should would work for GPT 3.5 or GPT 4 as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sVYOdeh0ZQ_v",
      "metadata": {
        "id": "sVYOdeh0ZQ_v"
      },
      "outputs": [],
      "source": [
        "!python3 learn-llm\\notebooks\\utils\\explainer.py\n",
        "sys.path.append('learn-llm/notebooks/utils')\n",
        "\n",
        "from explainer import Explainer\n",
        "\n",
        "explain = Explainer(DEFAULT_MODEL)\n",
        "# use this class if you want to get some explanations\n",
        "\n",
        "explain(\"difference between LLMs and other deep learning NLP models in a small table\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0711f6f",
      "metadata": {
        "id": "e0711f6f"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set the base URL and API key\n",
        "# For production apps it's preferable to use some secret management system and don't store the key in git repo :)\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url = DEFAULT_MODEL['api_base'],\n",
        "    api_key = DEFAULT_MODEL['api_key']\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d19e0b-73ea-45b9-aa45-60e597704dca",
      "metadata": {
        "id": "d8d19e0b-73ea-45b9-aa45-60e597704dca"
      },
      "source": [
        "## Completion VS ChatCompletion API:  \n",
        "There is also 2 variants of API or how to use these models, for example in Python: `Completion` and `ChatCompletion`.  \n",
        "\n",
        "## [Completion API](https://platform.openai.com/docs/guides/gpt/completions-api):  \n",
        "For the most common case you need to specify:\n",
        "* model name\n",
        "* prompt that will have the task for the model and should be a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba43208",
      "metadata": {
        "id": "0ba43208"
      },
      "outputs": [],
      "source": [
        "response = client.completions.create(\n",
        "    model=DEFAULT_MODEL[\"model\"],\n",
        "    prompt=\"Write a tagline for an ice cream shop.\",\n",
        "    temperature=0,\n",
        "    max_tokens=128,\n",
        "    n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3c17ec-304b-4ddc-a6f3-4a09e02fe00b",
      "metadata": {
        "id": "5b3c17ec-304b-4ddc-a6f3-4a09e02fe00b"
      },
      "outputs": [],
      "source": [
        "# Example of an output as an completion object:\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8658708a-2bc1-4aab-a831-92b9a4d33abd",
      "metadata": {
        "id": "8658708a-2bc1-4aab-a831-92b9a4d33abd"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e009b007-9b37-4deb-9605-91b4be5fee58",
      "metadata": {
        "id": "e009b007-9b37-4deb-9605-91b4be5fee58"
      },
      "source": [
        "Let's cover most important parameters for API:  \n",
        "- `temperature` -- aka randomness or 'creativity' of an output, `[0, 1]`. 0 -- no random, the output will be the same all the executions. 1 -- the output will be very different each execution.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b50c212a-0b03-4a0d-820f-ec9ae34258d7",
      "metadata": {
        "id": "b50c212a-0b03-4a0d-820f-ec9ae34258d7"
      },
      "outputs": [],
      "source": [
        "response = client.completions.create(\n",
        "    model=DEFAULT_MODEL[\"model\"],\n",
        "    prompt=\"Write a tagline for an ice cream shop.\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=128,\n",
        "    n=1,\n",
        ")\n",
        "print(response.choices[0].text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066a3580-95ff-4c61-853e-c35a5295f76e",
      "metadata": {
        "id": "066a3580-95ff-4c61-853e-c35a5295f76e"
      },
      "source": [
        "* `max_tokens` -- limits number of tokens in the output. It works like too low values will shrink your output, but not making the model to generate very short output!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd5b020d-4b5b-4aef-951e-32147d3f49f0",
      "metadata": {
        "id": "bd5b020d-4b5b-4aef-951e-32147d3f49f0"
      },
      "outputs": [],
      "source": [
        "response = client.completions.create(\n",
        "    model=DEFAULT_MODEL[\"model\"],\n",
        "    prompt=\"Write a tagline for an ice cream shop.\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=5,\n",
        "    n=1,\n",
        ")\n",
        "print(response.choices[0].text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060a6675-38e5-434b-8882-9b972f35a871",
      "metadata": {
        "id": "060a6675-38e5-434b-8882-9b972f35a871"
      },
      "source": [
        "* `n` -- how many output variants to generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4850b1ad-4e19-4066-8300-7ef34f320c20",
      "metadata": {
        "id": "4850b1ad-4e19-4066-8300-7ef34f320c20"
      },
      "outputs": [],
      "source": [
        "response = client.completions.create(\n",
        "    model=DEFAULT_MODEL[\"model\"],\n",
        "    prompt=\"Write a tagline for an ice cream shop.\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=128,\n",
        "    n=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94169ea9",
      "metadata": {
        "id": "94169ea9"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60ded41a",
      "metadata": {
        "id": "60ded41a"
      },
      "outputs": [],
      "source": [
        "print(response.choices[1].text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39b39b8-1b8f-4e01-acc4-f89d2bfcbdd4",
      "metadata": {
        "id": "e39b39b8-1b8f-4e01-acc4-f89d2bfcbdd4"
      },
      "source": [
        "Be aware, it's meaningless to use `n > 1` and `temperature == 0` since you will get `n` equal results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd35cf0-4221-4f8f-bc60-d1b4adaa1bfa",
      "metadata": {
        "id": "6fd35cf0-4221-4f8f-bc60-d1b4adaa1bfa"
      },
      "source": [
        "Other parameters you can check on official [OpenAI page](https://platform.openai.com/docs/api-reference/chat/create#chat/create-max_tokens:~:text=given%20chat%20conversation.-,Request%20body,-model)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5932a791-66c6-4170-a882-8a0f62466ebd",
      "metadata": {
        "id": "5932a791-66c6-4170-a882-8a0f62466ebd"
      },
      "source": [
        "## [ChatCompletion API](https://platform.openai.com/docs/guides/gpt/chat-completions-api):  \n",
        "\n",
        "For the most common case you need to specify:\n",
        "* model name\n",
        "* messages in the form of list of dictionaries; they will emulate a chat between a user and an assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c970684-b402-4c3f-a06a-54847feb19c0",
      "metadata": {
        "id": "9c970684-b402-4c3f-a06a-54847feb19c0"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=DEFAULT_MODEL[\"model\"],\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35698270-1d09-4247-b790-2ea51dc506f1",
      "metadata": {
        "id": "35698270-1d09-4247-b790-2ea51dc506f1"
      },
      "outputs": [],
      "source": [
        "# Example of an output completion object:\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d9403ca-f718-4f3b-bf84-482e2c4fb81f",
      "metadata": {
        "id": "7d9403ca-f718-4f3b-bf84-482e2c4fb81f"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "104baad5-b52f-4a55-8c38-339ebe8aea65",
      "metadata": {
        "id": "104baad5-b52f-4a55-8c38-339ebe8aea65"
      },
      "source": [
        "The **role** here is specifying who exactly sends the message, whether its from Human or from AI.  \n",
        "- **system role** is not required, but helpful to specify how a model should consider itself.  \n",
        "[From OpenAI documentation](https://platform.openai.com/docs/guides/gpt/chat-completions-api#:~:text=The%20system%20message,a%20helpful%20assistant.%22):  \n",
        "\"The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model‚Äôs behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"  \n",
        "- **human role** are possible inputs from the user helping a model to 'fit' on them\n",
        "- **assistant** -- examples of a desired behavior on the user's inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732f09c1-4c98-4e40-8e5d-939e4727fa1d",
      "metadata": {
        "id": "732f09c1-4c98-4e40-8e5d-939e4727fa1d"
      },
      "source": [
        "# üìù Prompt Engineering:  \n",
        "In this section we will cover:\n",
        "* Existing best techniques for prompt engineerging\n",
        "* Completion prompts for some Data Science tasks  \n",
        "\n",
        "\n",
        "*[References] This section is based on [DeepLearning.ai course](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction?_gl=1*tjnub9*_ga*MzgyMDU1MDc3LjE2ODMwNTU2MzE.*_ga_PZF1GBS1R1*MTY4Nzk0NjM3My45LjEuMTY4Nzk0Nzk4Ni4zOC4wLjA.).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b8e7fb-57c5-439f-9397-6a8b31c84c4d",
      "metadata": {
        "id": "38b8e7fb-57c5-439f-9397-6a8b31c84c4d"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt: str, system_prompt: str = None):\n",
        "    if system_prompt is None:\n",
        "        system_prompt = \"Just follow user instructions and don't communicate like \\\"Sure!\\\" or \\\"I hope this helps\\\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=DEFAULT_MODEL[\"model\"],\n",
        "    temperature=0,\n",
        "    max_tokens=256,\n",
        "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "              {\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a3a359a-566e-4af0-ba66-219e36a77283",
      "metadata": {
        "id": "6a3a359a-566e-4af0-ba66-219e36a77283"
      },
      "source": [
        "## Best practices:  \n",
        "Now let's observe and try different techniques helping you to construct a comprehensive and effective prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a85a877b-4474-4d6f-a3a9-b3f8d2d20304",
      "metadata": {
        "id": "a85a877b-4474-4d6f-a3a9-b3f8d2d20304"
      },
      "source": [
        "**1. Use delimiters to indicate distinct parts of the input clearly:**\n",
        "\n",
        "Delimiters can be anything like: ```, \"\"\", < >,¬†\\<tag> \\</tag>. It could help model focusing on specific parts of the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be353bde-5609-4d1f-907c-46c40835790f",
      "metadata": {
        "id": "be353bde-5609-4d1f-907c-46c40835790f"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Jupiter is the fifth planet from the Sun and the largest in the Solar System.\n",
        "It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half\n",
        "times that of all the other planets in the Solar System combined.\n",
        "Jupiter is one of the brightest objects visible to the naked eye in the night sky,\n",
        "and has been known to ancient civilizations since before recorded history.\n",
        "It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be\n",
        "bright enough for its reflected light to cast visible shadows,[20] and is on average\n",
        "the third-brightest natural object in the night sky after the Moon and Venus.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"Summarize the text delimited by triple backticks into a single sentence. ```{text}``` \"\"\"\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b42760-edf8-422a-9f91-c9ade8d2daca",
      "metadata": {
        "id": "e2b42760-edf8-422a-9f91-c9ade8d2daca"
      },
      "source": [
        "**2. Ask for a structured output:**\n",
        "\n",
        "You can as about JSON, HTML or any other reasonable format. JSON could be useful in many cases, let's try it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240f6033-c796-430f-a444-ff419ed16f0c",
      "metadata": {
        "id": "240f6033-c796-430f-a444-ff419ed16f0c"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along\n",
        "with their authors and genres. Provide them in JSON\n",
        "format with the following keys: book_id, title, author, genre.\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d4c9fa-6d5a-4705-a32d-f319a40646de",
      "metadata": {
        "id": "28d4c9fa-6d5a-4705-a32d-f319a40646de"
      },
      "source": [
        "**3. Ask the model to check whether conditions are satisfied:**  \n",
        "It's like `IF-ELSE` statement inside a prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04ccb70-b075-4290-b5fb-e63568e6f68b",
      "metadata": {
        "id": "b04ccb70-b075-4290-b5fb-e63568e6f68b"
      },
      "outputs": [],
      "source": [
        "recipe_w_steps = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some\n",
        " water boiling. While that's happening,\n",
        "grab a cup and put a tea bag in it. Once the water is\n",
        "hot enough, just pour it over the tea bag.\n",
        "Let it sit for a bit so the tea can steep. After a\n",
        "few minutes, take out the tea bag. If you\n",
        "like, you can add some sugar or milk to taste.\n",
        "And that's it! You've got yourself a delicious\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "\n",
        "recipe_wo_steps = f\"\"\"\n",
        "Making a cup of tea is easy! Just do it!\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = \"\"\"\n",
        "You will be provided with text delimited by triple quotes. If it contains some instructions, re-write those instructions in the following format:\n",
        "Step 1 - ... Step 2 - ... Step N - ...\n",
        "\n",
        "If provided text does not contain any instructions, simply write \\\"No steps provided.\\\".\n",
        "\n",
        "Text: \\\"\\\"\\\"{recipe}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "print(\"Steps provided:\\n\", generate_response(prompt=prompt.format(recipe=recipe_w_steps)))\n",
        "print(\"\\n\", \"-\"*30, \"\\n\")\n",
        "print(\"Steps missed:\\n\", generate_response(prompt=prompt.format(recipe=recipe_wo_steps)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37bf1a7-8869-45af-aaa2-a2897a17939c",
      "metadata": {
        "id": "e37bf1a7-8869-45af-aaa2-a2897a17939c"
      },
      "source": [
        "**4. Focus on specific aspects:**  \n",
        "Specifically ask a model to pay more attention on some details according to the task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90df4576-bdc8-47a2-ae07-c10ead40b45d",
      "metadata": {
        "id": "90df4576-bdc8-47a2-ae07-c10ead40b45d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "fact_sheet_chair = \"\"\"\n",
        "OVERVIEW\n",
        "- Part of a beautiful family of mid-century inspired office furniture,\n",
        "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
        "- Several options of shell color and base finishes.\n",
        "- Available with plastic back and front upholstery (SWC-100)\n",
        "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
        "- Base finish options are: stainless steel, matte black,\n",
        "gloss white, or chrome.\n",
        "- Chair is available with or without armrests.\n",
        "- Suitable for home or business settings.\n",
        "- Qualified for contract use.\n",
        "\n",
        "CONSTRUCTION\n",
        "- 5-wheel plastic coated aluminum base.\n",
        "- Pneumatic chair adjust for easy raise/lower action.\n",
        "\n",
        "DIMENSIONS\n",
        "- WIDTH 53 CM | 20.87‚Äù\n",
        "- DEPTH 51 CM | 20.08‚Äù\n",
        "- HEIGHT 80 CM | 31.50‚Äù\n",
        "- SEAT HEIGHT 44 CM | 17.32‚Äù\n",
        "- SEAT DEPTH 41 CM | 16.14‚Äù\n",
        "\n",
        "OPTIONS\n",
        "- Soft or hard-floor caster options.\n",
        "- Two choices of seat foam densities:\n",
        " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
        "- Armless or 8 position PU armrests\n",
        "\n",
        "MATERIALS\n",
        "SHELL BASE GLIDER\n",
        "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
        "- Shell thickness: 10 mm.\n",
        "SEAT\n",
        "- HD36 foam\n",
        "\n",
        "COUNTRY OF ORIGIN\n",
        "- Italy\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to help a marketing team create a description for a retail website of a product based on a technical fact sheet.\n",
        "Write a product description based on the information provided in the technical specifications delimited by triple backticks.\n",
        "\n",
        "The description is intended for furniture retailers, so should be technical in nature and focus on the materials the product is constructed from.\n",
        "\n",
        "Use at most 50 words.\n",
        "Technical specifications: ```{fact_sheet_chair}```\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b93c94-6075-47b1-83dc-fe8b0d8c26cb",
      "metadata": {
        "id": "28b93c94-6075-47b1-83dc-fe8b0d8c26cb"
      },
      "source": [
        "**5. Specify the model‚Äôs role:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95ca766-462b-413a-a8e6-0d1e7f91110f",
      "metadata": {
        "id": "c95ca766-462b-413a-a8e6-0d1e7f91110f"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are OrderBot - an automated service to collect orders for a pizza restaurant.\n",
        "You first greet the customer, then collects the order, and then asks if it's a pickup or delivery.\n",
        "You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else.\n",
        "\"\"\"\n",
        "\n",
        "# Please note that we provided this prompt to system prompt argument\n",
        "print(generate_response(prompt='Hi!', system_prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35dec9e3-089a-437f-91d2-50ab80475ef5",
      "metadata": {
        "id": "35dec9e3-089a-437f-91d2-50ab80475ef5"
      },
      "source": [
        "## Prompt examples for Data Science / Machine Learning tasks:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f847ed1-fecd-430d-a7bd-4482bf6002ba",
      "metadata": {
        "id": "0f847ed1-fecd-430d-a7bd-4482bf6002ba"
      },
      "outputs": [],
      "source": [
        "prod_review = \"\"\"\\\n",
        "Got this panda plush toy for my daughter's birthday, \\\n",
        "who loves it and takes it everywhere. It's soft and \\\n",
        "super cute, and its face has a friendly look. It's \\\n",
        "a bit small for what I paid though. I think there \\\n",
        "might be other options that are bigger for the \\\n",
        "same price. It arrived a day earlier than expected, \\\n",
        "so I got to play with it myself before I gave it \\\n",
        "to her.\\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7cade3-e51f-4033-9156-bfd473c15dd9",
      "metadata": {
        "id": "0a7cade3-e51f-4033-9156-bfd473c15dd9"
      },
      "source": [
        "**1. Summarization with focus:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc02f0a-91b1-4239-94db-98a281ab52d7",
      "metadata": {
        "id": "5fc02f0a-91b1-4239-94db-98a281ab52d7"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a short summary of a product review from an ecommerce site \\\n",
        "to give feedback to the pricing deparmtment, responsible for determining the price of the product.\n",
        "Summarize the review below in at most 30 words, and focusing on any aspects that are relevant to the price and perceived value.\n",
        "\n",
        "Review:\\n{prod_review}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61aeb86c-104f-4695-bc4b-b52a05684a07",
      "metadata": {
        "id": "61aeb86c-104f-4695-bc4b-b52a05684a07"
      },
      "source": [
        "**2. Information extraction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de89fd7b-5098-4687-877b-90c6c430cc73",
      "metadata": {
        "id": "de89fd7b-5098-4687-877b-90c6c430cc73"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the review below in order to give feedback to delivery department. Limit to 30 words.\n",
        "\n",
        "Review:\\n{prod_review}\n",
        "\n",
        "Feedback to delivery department:\\\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e1d6b4-e461-4dbb-9c13-3c6b4417f12d",
      "metadata": {
        "id": "b1e1d6b4-e461-4dbb-9c13-3c6b4417f12d"
      },
      "source": [
        "**3. Sentiment analysis:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb55d35d-3394-43ce-8c38-4d0e2bb05dd3",
      "metadata": {
        "id": "fb55d35d-3394-43ce-8c38-4d0e2bb05dd3"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\\\n",
        "Classify sentiment of the following product review.\n",
        "Give your answer as a single word, either \"positive\", \"negative\" or \"neutral\".\n",
        "\n",
        "Review:{prod_review}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0b4127-879b-4f6d-ace0-787d8ed1c185",
      "metadata": {
        "id": "ee0b4127-879b-4f6d-ace0-787d8ed1c185"
      },
      "source": [
        "**4. Entity Extraction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bd7741-f0d6-49f4-a987-dd14995f5288",
      "metadata": {
        "id": "46bd7741-f0d6-49f4-a987-dd14995f5288"
      },
      "outputs": [],
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the following entities from the text:\n",
        "\n",
        "Company name\n",
        "Date of contract\n",
        "Sum of contract\n",
        "Currency of a contract\n",
        "\n",
        "The review is delimited with triple backticks.\n",
        "Format your response as a JSON object with entities the keys and recoginized entities as values.\n",
        "If the information isn't present, use \"unknown\" as the value. Make your response as short as possible.\n",
        "\n",
        "Text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b269382-8b80-411b-83ed-3a435a39e34e",
      "metadata": {
        "id": "9b269382-8b80-411b-83ed-3a435a39e34e"
      },
      "source": [
        "**5. Topic recognition (open topics):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b8d691-ed63-4026-80b1-7a1569b68487",
      "metadata": {
        "id": "06b8d691-ed63-4026-80b1-7a1569b68487"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government,\n",
        "public sector employees were asked to rate their level\n",
        "of satisfaction with the department they work at.\n",
        "The results revealed that NASA was the most popular\n",
        "department with a satisfaction rating of 95%.\n",
        "\n",
        "One NASA employee, John Smith, commented on the findings,\n",
        "stating, \"I'm not surprised that NASA came out on top.\n",
        "It's a great place to work with amazing people and\n",
        "incredible opportunities. I'm proud to be a part of\n",
        "such an innovative organization.\"\n",
        "\n",
        "The results were also welcomed by NASA's management team,\n",
        "with Director Tom Johnson stating, \"We are thrilled to\n",
        "hear that our employees are satisfied with their work at NASA.\n",
        "We have a talented and dedicated team who work tirelessly\n",
        "to achieve our goals, and it's fantastic to see that their\n",
        "hard work is paying off.\"\n",
        "\n",
        "The survey also revealed that the\n",
        "Social Security Administration had the lowest satisfaction\n",
        "rating, with only 45% of employees indicating they were\n",
        "satisfied with their job. The government has pledged to\n",
        "address the concerns raised by employees in the survey and\n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb4ad74-0520-4a6b-b05f-eb722d7fb223",
      "metadata": {
        "id": "feb4ad74-0520-4a6b-b05f-eb722d7fb223"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the provided text.\n",
        "Make each item one or two words long.\n",
        "Give topics in Python list format.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c187751a-b60b-45cd-b445-4eed98435c81",
      "metadata": {
        "id": "c187751a-b60b-45cd-b445-4eed98435c81"
      },
      "source": [
        "**6. Topic recognition (closed list of topics):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26cc6a67-b9b3-4718-8352-99746a8b6724",
      "metadata": {
        "id": "26cc6a67-b9b3-4718-8352-99746a8b6724"
      },
      "outputs": [],
      "source": [
        "topic_list = [\"NASA\", \"Security\", \"Biology\"]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Recognize a topic from the given topic list delimited in triple backticks\n",
        "that is being discussed in the text, which is delimited by triple quotes. If you cannot determine between these 3, return 'other'.\n",
        "\n",
        "Topic list: ```{topic_list}```\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\n",
        "Provide an answer only with one word, representing a determined topic.\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d052637e-3947-437a-8caf-e517a856f288",
      "metadata": {
        "id": "d052637e-3947-437a-8caf-e517a856f288"
      },
      "source": [
        "**7. Translation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d70a74-a19b-4a7d-aceb-baf10c6ae1f5",
      "metadata": {
        "id": "d2d70a74-a19b-4a7d-aceb-baf10c6ae1f5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "text = \"Hello! How are you?\"\n",
        "system_prompt = \"Translate provided text to Spanish\"\n",
        "\n",
        "print(generate_response(prompt=text, system_prompt=system_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd71fdc-0388-4180-9cd9-a67c4d3ca96d",
      "metadata": {
        "id": "2cd71fdc-0388-4180-9cd9-a67c4d3ca96d"
      },
      "source": [
        "**8. Tone transforming:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4c458f-5922-46eb-9c2f-f286e833937a",
      "metadata": {
        "id": "ad4c458f-5922-46eb-9c2f-f286e833937a"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, man! Nice to see you. I will not be ready with my task, is it ok?\"\n",
        "prompt = f\"\"\" Translate the following from slang to a business letter: {text}. \"\"\"\n",
        "\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc7f54a7-b9c6-4872-8c1a-302afb03cfde",
      "metadata": {
        "id": "cc7f54a7-b9c6-4872-8c1a-302afb03cfde"
      },
      "source": [
        "**9. Spellcheck / Grammar check:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38712a8d-2a61-4df5-8645-ee58caecb4f9",
      "metadata": {
        "id": "38712a8d-2a61-4df5-8645-ee58caecb4f9"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, man! Nise to see you. I wont not be raedy with my task, it is ok?\"\n",
        "\n",
        "system_prompt = \"Proofread and correct user message. Explain made corrections.\"\n",
        "\n",
        "print(generate_response(prompt=text, system_prompt=system_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9f5353-4fe4-48e8-ae6f-d3820ad83455",
      "metadata": {
        "id": "4a9f5353-4fe4-48e8-ae6f-d3820ad83455"
      },
      "source": [
        "**10. Multiple tasks at the same time:**  \n",
        "Be aware that a prompt with multiple tasks tends to be less stable and correct than several prompts each for its own task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0d903f-4359-4c33-98a4-956d6732dbed",
      "metadata": {
        "id": "cf0d903f-4359-4c33-98a4-956d6732dbed"
      },
      "outputs": [],
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\" Identify the following items from the review text:\n",
        "\n",
        "Sentiment (positive or negative)\n",
        "Is the reviewer expressing anger? (true or false)\n",
        "Item purchased by reviewer\n",
        "Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks.\n",
        "Format your response as a JSON object with \"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\"as the value.\n",
        "Make your response as short as possible. Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "print(generate_response(prompt=prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc5ef29-7979-4d8b-9a13-70a7c0d71c6f",
      "metadata": {
        "id": "7bc5ef29-7979-4d8b-9a13-70a7c0d71c6f"
      },
      "source": [
        "These prompts could be a good baseline for your DS/ML task. You can consider them and add your own modifications, just make sure to avoid hallucinations and make them stable."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "toc-autonumbering": true
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
